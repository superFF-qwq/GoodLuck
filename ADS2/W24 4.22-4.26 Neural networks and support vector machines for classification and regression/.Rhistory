pd = pd1*p1 + pd2*p2 + pd3*p3 + pd4*p4 + pd5*p5 + pd6*p6
pd
# p(H1|D) = p(D|H1) * p(H1) / p(D)
p1d = pd1*p1/pd
p2d = pd2*p2/pd
p3d = pd3*p3/pd
p4d = pd4*p4/pd
p5d = pd5*p5/pd
p6d = pd6*p6/pd
p1d
p2d
p3d
p4d
p5d
p6d
which.max(c(p1d,p2d,p3d,p4d,p5d,p6d))
# p(D|H1) = 0.95
# p(D|H2) = 0.2
# p(H1) = 0.222
# p(H2) = 1 - 0.222
1 - 0.222
# p(D) = p(D|H1) * P(H1) + p(D}H2) * P(H2)
# p(D) = 0.95 * 0.222 + 0.2 * 0.778 =
0.95 * 0.222 + 0.2 * 0.778
# p(H1|D) = 0.95 * 0.222 / 0.3665
0.95 * 0.222 / 0.3665
# P(pregnant | test positive twice)
# D = test positive twice
# H1 = pregant
# H2 = non-pregnant
# P(pregnant | test positive twice) = p(H1|D) ?
# p(H1) = 0.222
# p(H2) = 1 - 0.222 = 0.778
# p(D|H1) = 0.95 * 0.95 =
0.95 * 0.95
# p(D|H2) = 0.2 * 0.2 = 0.04
# p(D) = p(D|H1) * P(H1) + p(D|H2) * p(H2) =
0.9025 * 0.222 + 0.04 * 0.778
# p(D|H1) * p(H1) = p(H1|D) * p(D)
# p(H1|D) = 0.9025 * 0.222 / 0.231475 =
0.9025 * 0.222 / 0.231475
# 其中A、B分别表示两组数据中某一发生和不发生的次数，
# C、D分别表示另一组数据中该发生和不发生的次数。
# 在流行病学研究中，OR值（odds ratio）是病例对照研究中的一个常用指标，
# 它指的是病例组中暴露人数与非暴露人数的比值除以对照组中暴露人数与非暴露人数的比值。
# OR值的具体意义如下：如果OR值等于1，表示该因素对疾病的发生不起作用；
# OR值大于1，表示该因素是危险因素；OR值小于1，表示该因素是保护因素。
#               pregnant   non-pregnant
# positive        0.95            0.2
# negative        0.05            0.8
# odds ratio = (0.95 / 0.05) / (0.2 / 0.8) =
(0.95 / 0.05) / (0.2 / 0.8)
# 其中A、B分别表示两组数据中某一发生和不发生的次数，
# C、D分别表示另一组数据中该发生和不发生的次数。
# 在流行病学研究中，OR值（odds ratio）是病例对照研究中的一个常用指标，
# 它指的是病例组中暴露人数与非暴露人数的比值除以对照组中暴露人数与非暴露人数的比值。
# OR值的具体意义如下：如果OR值等于1，表示该因素对疾病的发生不起作用；
# OR值大于1，表示该因素是危险因素；OR值小于1，表示该因素是保护因素。
#               test positive   test negative
# pregnant            0.95            0.05
# non-pregnant        0.2             0.8
# odds ratio = (0.95/0.2) / (0.05/0.8) =
(0.95/0.2) / (0.05/0.8)
# I feel the following is the correct format.
#               pregnant   non-pregnant
# positive        0.95            0.2
# negative        0.05            0.8
# odds ratio = (0.95/0.05) / (0.2/0.8) =
(0.95/0.05) / (0.2/0.8)
setwd("E:\\A大学\\大二下\\ADS2\\W24 4.22-4.26 Neural networks and support vector machines for classification and regression")
feature = read.csv("feature.csv")
setwd("E:\\A大学\\大二下\\ADS2\\W24 4.22-4.26 Neural networks and support vector machines for classification and regression")
data = read.csv("features.csv")
head(data)
data = data %>%
group_by(label) %>%
apply(2, mean)
library(readr)
library(dplyr)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(tidyr)
data = data %>%
group_by(label) %>%
apply(2, mean)
data
data = data %>%
group_by(label) %>%
apply(-instance, -label, 2, mean)
data = data %>%
group_by(label) %>%
apply(-instance, -label, 2, mean)
data = data %>%
group_by(label) %>%
apply(-instance, 2, mean)
data = data %>%
group_by(label) %>%
apply(-instance, MARGIN = 2, mean)
data[, -instance] =
apply(data[, -instance], MARGIN = 2, mean)
head(data)
data[, -instance]
head(data)
data[, -"instance"] =
apply(data[, -"instance"], MARGIN = 2, mean)
ncol(data)
nrow(data)
ncol(data)
ncol = length(colnames(data))
ncol
ncol = length(names(data))
ncol
data[, 2:ncol] =
apply(data[, 2:ncol], MARGIN = 2, mean)
dim(data[, 2:ncol])
dim(data[, 2:10])
data = read.csv("features.csv")
dim(data[, 2:10])
data2[, 2:ncol] =
apply(data[, 2:ncol], MARGIN = 2, mean)
data2 =
apply(data[, 2:ncol], MARGIN = 2, mean)
data2 = data
data2 = apply(data2[, 2:ncol], MARGIN = 2, mean)
data2
head(data2, 1)
head(data2)
str(data2)
data = data %>%
select(-instance) %>%
group_by(label) %>%
apply(MARGIN = 2, mean)
head(data)
data = read.csv("features.csv")
head(data)
data = data %>%
select(-instance) %>%
group_by(label) %>%
group_split() %>%
map(~{
apply(MARGIN = 2, mean)
})
data = data %>%
select(-instance) %>%
group_by(label) %>%
group_split() %>%
map(~{
apply(., MARGIN = 2, FUN = mean)
})
head(data)
ncol = length(names(data))
ncol
head(data)
View(data)
View(data)
data = data %>%
select(-instance) %>%
group_by(label) %>%
group_split() %>%
map(~{
apply(., MARGIN = 2, FUN = mean)
}) %>%
bind_rows()
data = read.csv("features.csv")
#head(data)
data = data[, -instance]
data = data[, -1]
data = data %>%
group_by(label) %>%
group_split() %>%
map(~{
apply(., MARGIN = 2, FUN = mean)
}) %>%
bind_rows()
head(data)
ncol = length(names(data))
ncol
data2 = data %>%
filter(label == 1 || label == 2)
data2 = data %>%
filter(label == 0 || label == 1) %>%
map(~{
tibble(x = rep(label, 56) , y = .[3:58])
})
# head(data)
# ncol = length(names(data))
# ncol
# head(data)
head(data)
data2 = data %>%
filter(label == 0 || label == 1)
data2 = data %>%
filter(label == 0 || label == 1)
data$label
data2 = data %>%
filter(label == 0 | label == 1)
data2
data2 = data %>%
filter(label == 0 | label == 1)
data2
data2 = data %>%
filter(label == 0 | label == 1) %>%
gather(feature, value, -label)
data2
nrow(data2)
data2 = data %>%
filter(label == 0 | label == 1) %>%
gather(feature, value, -label) %>%
mutate(feature = rep(1:nfeature, each = 2))
nfeature = ncol - 1
data2 = data %>%
filter(label == 0 | label == 1) %>%
gather(feature, value, -label) %>%
mutate(feature = rep(1:nfeature, each = 2))
data2
nrow(data2)
data2$label = as.factor(as.integer(data2$label))
# data2
# nrow(data2)
ggplot(data2, aes(x = feature, y = value, group = label)) +
geom_line()
# data2
# nrow(data2)
ggplot(data2, aes(x = feature, y = value, group = label, color = group)) +
geom_line()
ggplot(data2, aes(x = feature, y = value, group = label, color = group)) +
geom_line()
# data2
# nrow(data2)
ggplot(data2, aes(x = feature, y = value, group = label)) +
geom_line(aes(color = label))
nfeature = 56
# data
data2 = data %>%
filter(label == 0 | label == 1) %>%
gather(feature, value, -label) %>%
mutate(feature = rep(1:nfeature, each = 2))
nfeature = ncol - 1
# data
data2 = data %>%
filter(label == 0 | label == 1) %>%
gather(feature, value, -label) %>%
mutate(feature = rep(1:nfeature, each = 2))
data2$label = as.factor(as.integer(data2$label))
# data2
# nrow(data2)
ggplot(data2, aes(x = feature, y = value, group = label)) +
geom_line(aes(color = label))
data2 = data %>%
filter(label == 0 | label == 1) %>%
gather(feature, value, -label) %>%
mutate(feature = rep(1:nfeature, each = 2)) %>%
select(feature <= 56)
data2 = data %>%
filter(label == 0 | label == 1) %>%
gather(feature, value, -label) %>%
mutate(feature = rep(1:nfeature, each = 2)) %>%
filter(feature <= 56)
data2 = data %>%
filter(label == 0 | label == 1) %>%
gather(feature, value, -label) %>%
mutate(feature = rep(1:nfeature, each = 2)) %>%
filter(feature <= 56)
data2$label = as.factor(as.integer(data2$label))
# data2
# nrow(data2)
ggplot(data2, aes(x = feature, y = value, group = label)) +
geom_line(aes(color = label))
plot(x = 1:56, y = data2[label == 0,])
plot(x = 1:56, y = data2[label == 0,])
plot(x = 1:56, y = data2$value[data2$label == 0,])
plot(x = 1:56, y = data2$value[data2$label == 0])
lines(x = 1:56, y = data2$value[data2$label == 1])
lines(x = 1:56, y = data2$value[data2$label == 1], main = "")
library(nnet)
dot(x = 1:56, y = data2$value[data2$label == 0])
View(data2)
View(data2)
data3
data3 = data %>%
filter(label == 0 | label == 1) %>%
spread(-label, key = "feature", value = "value")
data3 = data2 %>%
filter(label == 0 | label == 1) %>%
spread(-label, key = "feature", value = "value")
data3 = data2 %>%
filter(label == 0 | label == 1) %>%
spread(key = "feature", value = "value")
data3
View(data3)
View(data3)
View(data3)
View(data3)
data3[, -1]
features = data2 %>%
filter(label == 0 | label == 1) %>%
spread(key = "feature", value = "value")
train_labels <- features[rows, 1]
rows <- sample(1:1000, 700)
train_labels <- features[rows, 1]
valid_labels <- features[-rows, 1]
train_data <- features[rows, -1]
valid_data <- features[-rows, -1]
train_labels_matrix = class.ind(train_labels)
train_labels_matrix = class.ind(train_labels)
train_labels_matrix = class.ind(as.matrix(train_labels))
head(as.matrix(train_labels))
head(train_labels)
View(features)
View(features)
head(train_labels)
features = data2 %>%
filter(label == 0 | label == 1) %>%
spread(key = "feature", value = "value")
features[rows, 1]
View(data)
View(data)
data0 = read.csv("features.csv")
View(data0)
View(data0)
features = data[, 2:57]
View(features)
View(features)
features = data0[, 2:57]
features = data0[, 2:57]
features = data0[, 2:57]
rows <- sample(1:1000, 700)
train_labels <- features[rows, 1]
valid_labels <- features[-rows, 1]
train_data <- features[rows, -1]
valid_data <- features[-rows, -1]
train_labels
head(train_labels)
train_labels_matrix = class.ind(train_labels)
head(train_labels_matrix)
nn = nnet(train_data, train_labels_matrix, size = 4, softmax = TRUE)
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
features = data0[, 2:57] / 255
rows <- sample(1:1000, 700)
train_labels <- features[rows, 1]
valid_labels <- features[-rows, 1]
train_data <- features[rows, -1]
valid_data <- features[-rows, -1]
head(train_labels)
train_labels_matrix = class.ind(train_labels)
head(train_labels_matrix)
## Now we are ready to train our neural network.
nn = nnet(train_data, train_labels_matrix, size = 4, softmax = TRUE)
# It will train a network with 4 hidden units (in one layer),
# performing 100 iterations by default.
# It indicates the number of weights (parameters) and
# development of errors with training.
# To use your train model for classifying data, use the predict command.
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
# will compute predicted classes for training and validation data
# You can calculate your classification accuracy by using
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
# for training and validation data.
nn = nnet(train_data, train_labels_matrix, size = 10, softmax = TRUE)
# It will train a network with 4 hidden units (in one layer),
# performing 100 iterations by default.
# It indicates the number of weights (parameters) and
# development of errors with training.
# To use your train model for classifying data, use the predict command.
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
# will compute predicted classes for training and validation data
# You can calculate your classification accuracy by using
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
nn = nnet(train_data, train_labels_matrix, size = 7, softmax = TRUE)
# It will train a network with 4 hidden units (in one layer),
# performing 100 iterations by default.
# It indicates the number of weights (parameters) and
# development of errors with training.
# To use your train model for classifying data, use the predict command.
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
# will compute predicted classes for training and validation data
# You can calculate your classification accuracy by using
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
nn = nnet(train_data, train_labels_matrix, size = 6, softmax = TRUE)
# It will train a network with 4 hidden units (in one layer),
# performing 100 iterations by default.
# It indicates the number of weights (parameters) and
# development of errors with training.
# To use your train model for classifying data, use the predict command.
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
# will compute predicted classes for training and validation data
# You can calculate your classification accuracy by using
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
# for training and validation data.
features = data0[, 2:57]
for(i in 2:57)
features[,i] = features[,i] / max(feature[,i])
features = data0[, 2:57]
for(i in 2:57)
features[,i] = features[,i] / max(features[,i])
features = data0[, 2:58]
for(i in 2:58)
features[,i] = features[,i] / max(features[,i])
features = data0[, 2:58]
for(i in 2:57)
features[,i] = features[,i] / max(features[,i])
features = data0[, 2:58]
for(i in 2:57)
features[,i] = features[,i] / max(features[,i])
rows <- sample(1:1000, 700)
train_labels <- features[rows, 1]
valid_labels <- features[-rows, 1]
train_data <- features[rows, -1]
valid_data <- features[-rows, -1]
head(train_labels)
train_labels_matrix = class.ind(train_labels)
head(train_labels_matrix)
## Now we are ready to train our neural network.
nn = nnet(train_data, train_labels_matrix, size = 6, softmax = TRUE)
for(i in 2:57){
maxi = max(features[,i])
if(maxi > 1e-3)
features[,i] = features[,i] / maxi
}
features = data0[, 2:58]
View(features)
for(i in 2:57){
maxi = max(features[,i])
if(maxi > 1e-3)
features[,i] = features[,i] / maxi
}
rows <- sample(1:1000, 700)
train_labels <- features[rows, 1]
valid_labels <- features[-rows, 1]
train_data <- features[rows, -1]
valid_data <- features[-rows, -1]
head(train_labels)
train_labels_matrix = class.ind(train_labels)
head(train_labels_matrix)
## Now we are ready to train our neural network.
nn = nnet(train_data, train_labels_matrix, size = 6, softmax = TRUE)
# It will train a network with 4 hidden units (in one layer),
# performing 100 iterations by default.
# It indicates the number of weights (parameters) and
# development of errors with training.
# To use your train model for classifying data, use the predict command.
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
# will compute predicted classes for training and validation data
# You can calculate your classification accuracy by using
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
# for training and validation data.
nn = nnet(train_data, train_labels_matrix, size = 10, softmax = TRUE)
# It will train a network with 4 hidden units (in one layer),
# performing 100 iterations by default.
# It indicates the number of weights (parameters) and
# development of errors with training.
# To use your train model for classifying data, use the predict command.
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
# will compute predicted classes for training and validation data
# You can calculate your classification accuracy by using
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
# for training and validation data.
nn = nnet(train_data, train_labels_matrix, size = 14, softmax = TRUE)
# It will train a network with 4 hidden units (in one layer),
# performing 100 iterations by default.
# It indicates the number of weights (parameters) and
# development of errors with training.
# To use your train model for classifying data, use the predict command.
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
# will compute predicted classes for training and validation data
# You can calculate your classification accuracy by using
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
# for training and validation data.
nn = nnet(train_data, train_labels_matrix, size = 12, softmax = TRUE)
# It will train a network with 4 hidden units (in one layer),
# performing 100 iterations by default.
# It indicates the number of weights (parameters) and
# development of errors with training.
# To use your train model for classifying data, use the predict command.
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
# will compute predicted classes for training and validation data
# You can calculate your classification accuracy by using
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
# for training and validation data.
nn = nnet(train_data, train_labels_matrix, size = 14, softmax = TRUE)
# It will train a network with 4 hidden units (in one layer),
# performing 100 iterations by default.
# It indicates the number of weights (parameters) and
# development of errors with training.
# To use your train model for classifying data, use the predict command.
pred_train = predict(nn, train_data, type="class")
pred_valid = predict(nn, valid_data, type="class")
# will compute predicted classes for training and validation data
# You can calculate your classification accuracy by using
mean(pred_train == train_labels)
mean(pred_valid == valid_labels)
# for training and validation data.
